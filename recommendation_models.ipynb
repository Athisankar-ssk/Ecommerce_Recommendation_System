{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5bc6039-ee2f-492f-9193-57890f94b454",
   "metadata": {},
   "source": [
    "Popularity-Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437670f8-83a9-49c8-90b9-fcf89b1e2f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Popular Products:\n",
      "                 product_name  purchase_count\n",
      "3677                   Banana          491291\n",
      "3472   Bag of Organic Bananas          394930\n",
      "31923    Organic Strawberries          275577\n",
      "28843    Organic Baby Spinach          251705\n",
      "30300    Organic Hass Avocado          220877\n",
      "28807         Organic Avocado          184224\n",
      "22415             Large Lemon          160792\n",
      "42908            Strawberries          149445\n",
      "23422                   Limes          146660\n",
      "32481      Organic Whole Milk          142813\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load datasets\n",
    "orders_merged = pd.read_csv(\"orders_merged.csv\")\n",
    "products_cleaned = pd.read_csv(\"products_cleaned.csv\")\n",
    "\n",
    "# Step 3: Merge orders with products to get product names\n",
    "order_details = pd.merge(orders_merged, products_cleaned, on='product_id', how='left')\n",
    "\n",
    "# Step 4: Calculate product popularity\n",
    "product_popularity = order_details.groupby('product_name').size().reset_index(name='purchase_count')\n",
    "\n",
    "# Step 5: Sort by popularity\n",
    "top_products = product_popularity.sort_values(by='purchase_count', ascending=False)\n",
    "\n",
    "# Step 6: Display top 10 products\n",
    "print(\"Top 10 Popular Products:\")\n",
    "print(top_products.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a9ed8b-f93d-4d66-b2b5-4687419e3719",
   "metadata": {},
   "source": [
    "ALS stands for Alternating Least Squares — it’s a popular algorithm for collaborative filtering in recommendation systems.\n",
    "\n",
    "Here’s the simple idea:\n",
    "\n",
    "    You have a big table (matrix) of users × items (e.g., customers × products).\n",
    "    \n",
    "    Most of the cells are empty because users only rate/buy a few items.\n",
    "    \n",
    "    ALS tries to fill in the missing cells by finding patterns in what similar users like.\n",
    "\n",
    "Why it’s used:\n",
    "\n",
    "    Handles large sparse datasets well (like e-commerce purchase history).\n",
    "    \n",
    "    Works even without explicit ratings (can use purchase counts or implicit feedback).\n",
    "    \n",
    "    Scales well for big data with frameworks like Spark or implicit library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afea4a18-57bd-4fd7-97bf-4a7ccf4fb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akram\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb80b1c8a1d74447a09cee8e9f3d2ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing user (user_id=1):\n",
      "+--------+--------------+----------------+--------------+\n",
      "|   Rank |   Product ID | Product Name   |        Score |\n",
      "+========+==============+================+==============+\n",
      "|      1 |          103 | Milk           |  0.0196556   |\n",
      "+--------+--------------+----------------+--------------+\n",
      "|      2 |          104 | Bread          |  6.60792e-05 |\n",
      "+--------+--------------+----------------+--------------+\n",
      "|      3 |          105 | Eggs           |  2.54475e-05 |\n",
      "+--------+--------------+----------------+--------------+\n",
      "|      4 |          102 | Apples         | -3.40282e+38 |\n",
      "+--------+--------------+----------------+--------------+\n",
      "|      5 |          101 | Bananas        | -3.40282e+38 |\n",
      "+--------+--------------+----------------+--------------+\n",
      "\n",
      "Cold start user (user_id=999):\n",
      "+--------+--------------+----------------+---------+\n",
      "|   Rank |   Product ID | Product Name   | Score   |\n",
      "+========+==============+================+=========+\n",
      "|      1 |          101 | Bananas        |         |\n",
      "+--------+--------------+----------------+---------+\n",
      "|      2 |          103 | Milk           |         |\n",
      "+--------+--------------+----------------+---------+\n",
      "|      3 |          104 | Bread          |         |\n",
      "+--------+--------------+----------------+---------+\n",
      "|      4 |          105 | Eggs           |         |\n",
      "+--------+--------------+----------------+---------+\n",
      "|      5 |          102 | Apples         |         |\n",
      "+--------+--------------+----------------+---------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(101, 'Bananas', None),\n",
       " (103, 'Milk', None),\n",
       " (104, 'Bread', None),\n",
       " (105, 'Eggs', None),\n",
       " (102, 'Apples', None)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from tabulate import tabulate  # pip install tabulate\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load your data\n",
    "# -------------------------------\n",
    "# Example dummy data (replace with Instacart dataset)\n",
    "interactions = pd.DataFrame({\n",
    "    'user_id': [1, 1, 2, 2, 3, 4],\n",
    "    'product_id': [101, 102, 101, 103, 104, 105],\n",
    "    'purchase_count': [3, 1, 2, 5, 4, 2]\n",
    "})\n",
    "\n",
    "products = pd.DataFrame({\n",
    "    'product_id': [101, 102, 103, 104, 105],\n",
    "    'product_name': ['Bananas', 'Apples', 'Milk', 'Bread', 'Eggs']\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Build index mappings\n",
    "# -------------------------------\n",
    "user_index = interactions['user_id'].unique()\n",
    "item_index = interactions['product_id'].unique()\n",
    "\n",
    "user_index_map = {u: i for i, u in enumerate(user_index)}\n",
    "item_index_map = {p: i for i, p in enumerate(item_index)}\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Build user-item CSR matrix\n",
    "# -------------------------------\n",
    "row = interactions['user_id'].map(user_index_map)\n",
    "col = interactions['product_id'].map(item_index_map)\n",
    "data = interactions['purchase_count']\n",
    "\n",
    "user_item_csr = csr_matrix((data, (row, col)), shape=(len(user_index), len(item_index)))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Train ALS model\n",
    "# -------------------------------\n",
    "model = AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)\n",
    "model.fit(user_item_csr)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Precompute popularity fallback\n",
    "# -------------------------------\n",
    "product_popularity = (\n",
    "    interactions.groupby('product_id')['purchase_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .index[:50]  # top 50 popular products\n",
    ")\n",
    "\n",
    "item_index = np.array(item_index)  # ensure numpy for position indexing\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Safe recommendation function\n",
    "# -------------------------------\n",
    "def recommend_als_safe(raw_user_id, N=10):\n",
    "    # Cold-start: user not in training set\n",
    "    if raw_user_id not in user_index:\n",
    "        recs = [\n",
    "            (pid, products.loc[products['product_id'] == pid, 'product_name'].values[0], None)\n",
    "            for pid in product_popularity[:N]\n",
    "        ]\n",
    "        print(tabulate(\n",
    "            [(i+1, pid, name, score) for i, (pid, name, score) in enumerate(recs)],\n",
    "            headers=[\"Rank\", \"Product ID\", \"Product Name\", \"Score\"],\n",
    "            tablefmt=\"grid\"\n",
    "        ))\n",
    "        return recs\n",
    "\n",
    "    # Map raw user ID to ALS index\n",
    "    uidx = np.where(user_index == raw_user_id)[0][0]\n",
    "\n",
    "    # Get ALS recommendations\n",
    "    ids, scores = model.recommend(uidx, user_item_csr[uidx], N=N, filter_already_liked_items=True)\n",
    "\n",
    "    # Map back to product IDs\n",
    "    prod_ids = [item_index[i] for i in ids]\n",
    "\n",
    "    # Match with product names\n",
    "    prod_df = products.set_index('product_id')\n",
    "    recs = [\n",
    "        (pid,\n",
    "         prod_df.loc[pid, 'product_name'] if pid in prod_df.index else None,\n",
    "         score)\n",
    "        for pid, score in zip(prod_ids, scores)\n",
    "    ]\n",
    "\n",
    "    print(tabulate(\n",
    "        [(i+1, pid, name, score) for i, (pid, name, score) in enumerate(recs)],\n",
    "        headers=[\"Rank\", \"Product ID\", \"Product Name\", \"Score\"],\n",
    "        tablefmt=\"grid\"\n",
    "    ))\n",
    "    return recs\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Test the function\n",
    "# -------------------------------\n",
    "print(\"Existing user (user_id=1):\")\n",
    "recommend_als_safe(1, N=5)\n",
    "\n",
    "print(\"\\nCold start user (user_id=999):\")\n",
    "recommend_als_safe(999, N=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb9488e-73f4-4c99-aaac-1af1d92e2512",
   "metadata": {},
   "source": [
    "Collaborative Filtering \n",
    "\n",
    "\n",
    "    1.User-Based Collaborative Filtering (UBCF) – finds users similar to the target user and recommends items those similar users liked.\n",
    "\n",
    "    2.Item-Based Collaborative Filtering (IBCF) – finds items similar to the ones the target user liked and recommends them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343fe17b-ca25-4859-8e09-0a63e803ae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 items similar to Product 196:\n",
      "[(46149, np.float64(0.2870940256440365)), (37710, np.float64(0.2502117928605355)), (6184, np.float64(0.22958867591648727)), (41400, np.float64(0.22715170546482377)), (38928, np.float64(0.20335099832315626))]\n"
     ]
    }
   ],
   "source": [
    "# Item-Based Collaborative Filtering (Memory-Safe Version)\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ===== 1. Load your cleaned & merged data =====\n",
    "# Replace with your actual file path\n",
    "df = pd.read_csv(\"user_product_interactions.csv\")\n",
    "\n",
    "# Ensure correct column names\n",
    "# Must contain: user_id, product_id\n",
    "df = df[['user_id', 'product_id']]\n",
    "\n",
    "# ===== 2. Create User-Item Sparse Matrix =====\n",
    "# Map IDs to index positions\n",
    "user_ids = df['user_id'].astype(\"category\").cat.codes\n",
    "item_ids = df['product_id'].astype(\"category\").cat.codes\n",
    "\n",
    "# Sparse matrix: rows = users, cols = items\n",
    "user_item_matrix = csr_matrix(\n",
    "    ( [1]*len(df), (user_ids, item_ids) )\n",
    ")\n",
    "\n",
    "# Reverse mapping for later\n",
    "item_id_map = dict(enumerate(df['product_id'].astype(\"category\").cat.categories))\n",
    "\n",
    "# ===== 3. Function: Get Top-N Similar Items =====\n",
    "def get_top_n_similar_items(target_item_id, top_n=5):\n",
    "    target_idx = list(item_id_map.keys())[list(item_id_map.values()).index(target_item_id)]\n",
    "    \n",
    "    # Get column vector for target item\n",
    "    target_vector = user_item_matrix[:, target_idx]\n",
    "    \n",
    "    # Compute cosine similarity with all other items\n",
    "    sims = cosine_similarity(target_vector.T, user_item_matrix.T).flatten()\n",
    "    \n",
    "    # Get top N excluding self\n",
    "    similar_indices = sims.argsort()[::-1][1:top_n+1]\n",
    "    similar_scores = sims[similar_indices]\n",
    "    \n",
    "    # Map indices back to product IDs\n",
    "    similar_items = [(item_id_map[i], score) for i, score in zip(similar_indices, similar_scores)]\n",
    "    \n",
    "    return similar_items\n",
    "\n",
    "# ===== 4. Example Usage =====\n",
    "target_product = df['product_id'].iloc[0]\n",
    "print(f\"Top 5 items similar to Product {target_product}:\")\n",
    "print(get_top_n_similar_items(target_product, top_n=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11dabcd4-1323-420f-a2f7-4f5077aa21fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user: 66\n",
      "[(24852, 'Banana'), (26209, 'Limes'), (47626, 'Large Lemon'), (20114, 'Jalapeno Peppers'), (29487, 'Roma Tomato')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# -----------------------\n",
    "# 1. Load & Prepare Data\n",
    "# -----------------------\n",
    "data = pd.read_csv(\"orders_merged.csv\")\n",
    "\n",
    "# 🔹 Optional: work only with first 5000 users to debug\n",
    "subset_users = data['user_id'].drop_duplicates().head(5000)\n",
    "data = data[data['user_id'].isin(subset_users)]\n",
    "\n",
    "# Encode user_id and product_id as category codes\n",
    "user_cat = data['user_id'].astype(\"category\")\n",
    "item_cat = data['product_id'].astype(\"category\")\n",
    "\n",
    "user_ids = user_cat.cat.codes\n",
    "item_ids = item_cat.cat.codes\n",
    "\n",
    "# Keep mapping dictionaries for decoding later\n",
    "user_id_map = dict(enumerate(user_cat.cat.categories))     # code → real user_id\n",
    "product_id_map = dict(enumerate(item_cat.cat.categories))  # code → real product_id\n",
    "\n",
    "# If you have product metadata (names), load it\n",
    "products = pd.read_csv(\"products_cleaned.csv\")  # must have product_id, product_name\n",
    "product_lookup = products.set_index(\"product_id\")[\"product_name\"].to_dict()\n",
    "\n",
    "# Sparse matrix\n",
    "values = [1] * len(data)\n",
    "interaction_matrix = csr_matrix(\n",
    "    (values, (user_ids, item_ids)),\n",
    "    shape=(len(user_id_map), len(product_id_map))\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 2. Recommend for One User\n",
    "# -----------------------\n",
    "def recommend_for_user(user_index, top_n=5, top_k_users=50):\n",
    "    \"\"\"Recommend items for a given user without building full similarity matrix.\"\"\"\n",
    "\n",
    "    # Target user's vector\n",
    "    user_vector = interaction_matrix[user_index]\n",
    "\n",
    "    # Cosine similarity with all users\n",
    "    similarities = cosine_similarity(user_vector, interaction_matrix).ravel()\n",
    "\n",
    "    # Exclude self\n",
    "    similarities[user_index] = 0\n",
    "\n",
    "    # Get top-k similar users\n",
    "    top_users = similarities.argsort()[::-1][:top_k_users]\n",
    "\n",
    "    # Aggregate items from similar users\n",
    "    similar_items = interaction_matrix[top_users].sum(axis=0)\n",
    "    similar_items = np.array(similar_items).ravel()\n",
    "\n",
    "    # Remove already purchased items\n",
    "    purchased_items = user_vector.toarray().ravel()\n",
    "    similar_items[purchased_items > 0] = 0\n",
    "\n",
    "    # Recommend top-N (item indices)\n",
    "    top_items = similar_items.argsort()[::-1][:top_n]\n",
    "\n",
    "    # Convert to real product IDs + names\n",
    "    recs = []\n",
    "    for idx in top_items:\n",
    "        pid = product_id_map[idx]\n",
    "        pname = product_lookup.get(pid, \"Unknown Product\")\n",
    "        recs.append((pid, pname))\n",
    "\n",
    "    return recs\n",
    "\n",
    "# Example: Recommend for first user in subset\n",
    "print(\"Recommendations for user:\", user_id_map[0])\n",
    "print(recommend_for_user(0, top_n=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c663b9-6619-4d5e-9694-fe0ab980a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based recommendations for 24852:\n",
      "       product_id    product_name         aisle department\n",
      "7888         7889      Red Banana  fresh fruits    produce\n",
      "14926       14927       Blueberry  fresh fruits    produce\n",
      "28554       28555         Coconut  fresh fruits    produce\n",
      "30556       30557  Manzano Banana  fresh fruits    produce\n",
      "37066       37067  Organic Banana  fresh fruits    produce\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Load product metadata\n",
    "products = pd.read_csv(\"products_cleaned.csv\")\n",
    "\n",
    "# 2. Create combined text field\n",
    "products['products_cleaned'] = (\n",
    "    products['product_name'].astype(str) + \" \" +\n",
    "    products['aisle'].astype(str) + \" \" +\n",
    "    products['department'].astype(str)\n",
    ")\n",
    "\n",
    "# 3. Drop duplicates\n",
    "product_metadata = products[['product_id', 'products_cleaned']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 4. TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(product_metadata['products_cleaned'])  # stays sparse\n",
    "\n",
    "# Map product_id ↔ row index\n",
    "id_to_index = pd.Series(product_metadata.index, index=product_metadata['product_id'])\n",
    "index_to_id = pd.Series(product_metadata['product_id'].values, index=product_metadata.index)\n",
    "\n",
    "# 5. Recommend function (no full similarity matrix!)\n",
    "def recommend_similar_products(product_id, top_n=5):\n",
    "    if product_id not in id_to_index:\n",
    "        return []\n",
    "    \n",
    "    idx = id_to_index[product_id]\n",
    "    sim_scores = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).ravel()\n",
    "    top_indices = sim_scores.argsort()[::-1][1:top_n+1]\n",
    "    recommended_ids = index_to_id[top_indices].tolist()\n",
    "    \n",
    "    # Map back to names\n",
    "    results = products[products['product_id'].isin(recommended_ids)][['product_id', 'product_name', 'aisle', 'department']]\n",
    "    return results\n",
    "\n",
    "# Example\n",
    "print(\"Content-based recommendations for 24852:\")\n",
    "print(recommend_similar_products(24852, top_n=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95172a01-2ed5-4dcd-b79d-07a0f44c1293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
